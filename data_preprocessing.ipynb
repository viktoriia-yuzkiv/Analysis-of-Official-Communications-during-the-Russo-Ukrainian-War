{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc8ecfc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469edc0e",
   "metadata": {},
   "source": [
    "This is the pre-processing notebook for the European Commission and White House datasets. This notebook aims to standardize and prepare the data for analysis. Here are the main steps:\n",
    "\n",
    "- Casting Date Format: Standardizing date format for consistency.\n",
    "- Filtering Data: Including records from 2021-2023 for three-year panel data (so that we have 2021 for pre-war comparison as well).\n",
    "- Updating Category Names: Unifying category labels across datasets.\n",
    "- Excluding Non-English Texts (EC Dataset): Removing non-English texts for data integrity.\n",
    "- Lemmatizing Data: Reducing words to base form for analysis.\n",
    "- Adding Binary Column for Mentions of Ukraine: Identifying mentions of Ukraine for analysis.\n",
    "\n",
    "These steps ensure data consistency and usability for insightful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3801729",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109d3c6",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44676dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/viktoriia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "#getting a library of stopwords and defining a lemmatizer\n",
    "porter=SnowballStemmer(\"english\")\n",
    "lmtzr = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06066a",
   "metadata": {},
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53189a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(word):\n",
    "    mod_string = re.sub(r'\\W+', '', word)\n",
    "    return mod_string\n",
    "\n",
    "\n",
    "# The following leaves in place two or more capital letters in a row\n",
    "# Will be ignored when using standard stemming\n",
    "def abbr_or_lower(word):\n",
    "    if re.match('([A-Z]+[a-z]*){2,}', word):\n",
    "        return word\n",
    "    else:\n",
    "        return word.lower()\n",
    "\n",
    "# Modular pipeline for stemming, lemmatizing and lowercasing\n",
    "# Note this is NOT lemmatizing using grammar pos\n",
    "    \n",
    "def tokenize(text, modulation):\n",
    "    if modulation<2:\n",
    "        tokens = re.split(r'\\W+', text)\n",
    "        stems = []\n",
    "        # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "        for token in tokens:\n",
    "            lowers=abbr_or_lower(token)\n",
    "            if lowers not in stop_words:\n",
    "                if re.search('[a-zA-Z]', lowers):\n",
    "                    if modulation==0:\n",
    "                        stems.append(lowers)\n",
    "                    if modulation==1:\n",
    "                        stems.append(porter.stem(lowers))\n",
    "    else:\n",
    "        sp_text=sp(text)\n",
    "        stems = []\n",
    "        lemmatized_text=[]\n",
    "        for word in sp_text:\n",
    "            lemmatized_text.append(word.lemma_)\n",
    "        stems = [abbr_or_lower(strip(w)) for w in lemmatized_text if (abbr_or_lower(strip(w))) and (abbr_or_lower(strip(w)) not in stop_words)]\n",
    "    return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0117bf",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf4035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joint press statement by the President of the ...</td>\n",
       "      <td>8 February 2024</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>On 8 February 2024 Her Excellency, President o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Press statement by President von der Leyen fol...</td>\n",
       "      <td>8 February 2024</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>President Ghazouani,\\nThank you for your warm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opening remarks by President von der Leyen at ...</td>\n",
       "      <td>1 February 2024</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>Today is a very special day. The European Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICJ: Joint Statement by the High Representativ...</td>\n",
       "      <td>26 January 2024</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>We take note of today's order of the Internati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Statement by the Commission and High Represent...</td>\n",
       "      <td>26 January 2024</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>We are extremely concerned by allegations of U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Date  \\\n",
       "0  Joint press statement by the President of the ...  8 February 2024   \n",
       "1  Press statement by President von der Leyen fol...  8 February 2024   \n",
       "2  Opening remarks by President von der Leyen at ...  1 February 2024   \n",
       "3  ICJ: Joint Statement by the High Representativ...  26 January 2024   \n",
       "4  Statement by the Commission and High Represent...  26 January 2024   \n",
       "\n",
       "    Category                                               Text  \n",
       "0  STATEMENT  On 8 February 2024 Her Excellency, President o...  \n",
       "1  STATEMENT  President Ghazouani,\\nThank you for your warm ...  \n",
       "2  STATEMENT  Today is a very special day. The European Coun...  \n",
       "3  STATEMENT  We take note of today's order of the Internati...  \n",
       "4  STATEMENT  We are extremely concerned by allegations of U...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the European Commission data\n",
    "ec_data = pd.read_csv('data/theeuropeancommission.csv')\n",
    "ec_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0af58f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remarks by President Biden and Vice President ...</td>\n",
       "      <td>2024-02-03T22:00:00-05:00</td>\n",
       "      <td>Speeches and Remarks</td>\n",
       "      <td>Biden for President Campaign Headquarters; Wil...</td>\n",
       "      <td>THE VICE PRESIDENT:  Hello, Delaware!  (Applau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remarks by Vice President Harris at a Campaign...</td>\n",
       "      <td>2024-02-02T23:33:00-05:00</td>\n",
       "      <td>Speeches and Remarks</td>\n",
       "      <td>South Carolina State University; Orangeburg, S...</td>\n",
       "      <td>THE VICE PRESIDENT:  All right.  Can we hear i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remarks by President Biden at a Political Even...</td>\n",
       "      <td>2024-02-01T20:24:19-05:00</td>\n",
       "      <td>Speeches and Remarks</td>\n",
       "      <td>Region 1 Union Hall; Warren, Michigan</td>\n",
       "      <td>4:41 P.M. EST\\n \\nTHE PRESIDENT:  Well, thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remarks by President Biden at the National Pra...</td>\n",
       "      <td>2024-02-01T14:13:03-05:00</td>\n",
       "      <td>Speeches and Remarks</td>\n",
       "      <td>U.S. Capitol; Washington, D.C.</td>\n",
       "      <td>9:04 A.M. EST\\nTHE PRESIDENT:  Frank, thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remarks by President Biden at a Campaign Recep...</td>\n",
       "      <td>2024-01-31T00:04:32-05:00</td>\n",
       "      <td>Speeches and Remarks</td>\n",
       "      <td>Private Residence; Miami, Florida</td>\n",
       "      <td>6:27 P.M. EST\\n\\nTHE PRESIDENT: Well, Chris, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Remarks by President Biden and Vice President ...   \n",
       "1  Remarks by Vice President Harris at a Campaign...   \n",
       "2  Remarks by President Biden at a Political Even...   \n",
       "3  Remarks by President Biden at the National Pra...   \n",
       "4  Remarks by President Biden at a Campaign Recep...   \n",
       "\n",
       "                        Date              Category  \\\n",
       "0  2024-02-03T22:00:00-05:00  Speeches and Remarks   \n",
       "1  2024-02-02T23:33:00-05:00  Speeches and Remarks   \n",
       "2  2024-02-01T20:24:19-05:00  Speeches and Remarks   \n",
       "3  2024-02-01T14:13:03-05:00  Speeches and Remarks   \n",
       "4  2024-01-31T00:04:32-05:00  Speeches and Remarks   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Biden for President Campaign Headquarters; Wil...   \n",
       "1  South Carolina State University; Orangeburg, S...   \n",
       "2              Region 1 Union Hall; Warren, Michigan   \n",
       "3                     U.S. Capitol; Washington, D.C.   \n",
       "4                  Private Residence; Miami, Florida   \n",
       "\n",
       "                                                Text  \n",
       "0  THE VICE PRESIDENT:  Hello, Delaware!  (Applau...  \n",
       "1  THE VICE PRESIDENT:  All right.  Can we hear i...  \n",
       "2  4:41 P.M. EST\\n \\nTHE PRESIDENT:  Well, thank ...  \n",
       "3  9:04 A.M. EST\\nTHE PRESIDENT:  Frank, thank yo...  \n",
       "4  6:27 P.M. EST\\n\\nTHE PRESIDENT: Well, Chris, t...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the White House data\n",
    "wh_data = pd.read_csv('data/thewhitehouse.csv')\n",
    "wh_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3ae57",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415540e",
   "metadata": {},
   "source": [
    "## The European Commission data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c3f7e",
   "metadata": {},
   "source": [
    "#### Clean the Date column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0a4212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European Commission authorises second safe and...</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>PRESS RELEASE</td>\n",
       "      <td>Today, the European Commission has granted a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement by President von der Leyen on the re...</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>STATEMENT</td>\n",
       "      <td>What happened in Washington yesterday is as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commission proposes to purchase up to 300 mill...</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>PRESS RELEASE</td>\n",
       "      <td>The European Commission today proposed to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speech by President von der Leyen at the One P...</td>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>SPEECH</td>\n",
       "      <td>Merci Monsieur le Président.\\nCher Emmanuel,\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coronavirus: Commission concludes exploratory ...</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>PRESS RELEASE</td>\n",
       "      <td>Today, the European Commission concluded explo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Date  \\\n",
       "0  European Commission authorises second safe and... 2021-01-06   \n",
       "1  Statement by President von der Leyen on the re... 2021-01-07   \n",
       "2  Commission proposes to purchase up to 300 mill... 2021-01-08   \n",
       "3  Speech by President von der Leyen at the One P... 2021-01-11   \n",
       "4  Coronavirus: Commission concludes exploratory ... 2021-01-12   \n",
       "\n",
       "        Category                                               Text  \n",
       "0  PRESS RELEASE  Today, the European Commission has granted a c...  \n",
       "1      STATEMENT    What happened in Washington yesterday is as ...  \n",
       "2  PRESS RELEASE  The European Commission today proposed to the ...  \n",
       "3         SPEECH  Merci Monsieur le Président.\\nCher Emmanuel,\\n...  \n",
       "4  PRESS RELEASE  Today, the European Commission concluded explo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "ec_data['Date'] = pd.to_datetime(ec_data['Date'], format='%d %B %Y')\n",
    "\n",
    "# Filter out dates between 2021 and 2023 so we have 3 years panel data\n",
    "ec_data = ec_data[(ec_data['Date'] >= '2021-01-01') & (ec_data['Date'] <= '2023-12-31')]\n",
    "\n",
    "# Sort the dataset in the ascending order of date\n",
    "ec_data = ec_data.sort_values(by = 'Date', ignore_index=True)\n",
    "\n",
    "ec_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4d90e",
   "metadata": {},
   "source": [
    "#### Ensure that the category names are aligned between the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba4f9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STATEMENT', 'SPEECH', 'PRESS RELEASE'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_data.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b17e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the replacement dictionary\n",
    "replacement_dict = {\n",
    "    'PRESS RELEASE': 'Press Release',\n",
    "    'STATEMENT': 'Statement',\n",
    "    'SPEECH': 'Speech'\n",
    "}\n",
    "\n",
    "# Replace values in the 'column_name' column using the replace() method\n",
    "ec_data['Category'] = ec_data['Category'].replace(replacement_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb718d35",
   "metadata": {},
   "source": [
    "#### Check for Null values and duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40f4497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title       0\n",
       "Date        0\n",
       "Category    0\n",
       "Text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "ec_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3933fcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "ec_data.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46762e21",
   "metadata": {},
   "source": [
    "There are no Null values and duplicates in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258a762",
   "metadata": {},
   "source": [
    "#### Exclude texts that are not in English from the dataset:\n",
    "\n",
    "Upon observation, we identified texts within the dataset that are not in English. To streamline further analysis and ensure consistency, we've opted to remove these non-English texts from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be533be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-English articles: 21\n"
     ]
    }
   ],
   "source": [
    "# Drop articles that are not in English\n",
    "\n",
    "non_en_count = 0\n",
    "for index, row in ec_data.iterrows():\n",
    "    lang = detect(row['Text'])\n",
    "    if lang != 'en':  # 'en' represents English\n",
    "        non_en_count +=1\n",
    "        ec_data = ec_data.drop(index=index)\n",
    "print(f'Number of non-English articles: {non_en_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19775e",
   "metadata": {},
   "source": [
    "#### Pre-process titles and texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f724786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1078/1078 [02:57<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with text!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1078/1078 [00:04<00:00, 225.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with titles!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1078 entries, 0 to 1098\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Title           1078 non-null   object        \n",
      " 1   Date            1078 non-null   datetime64[ns]\n",
      " 2   Category        1078 non-null   object        \n",
      " 3   Text            1078 non-null   object        \n",
      " 4   text_preproc    1078 non-null   object        \n",
      " 5   titles_preproc  1078 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 59.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 - lowercase, 1 - stemming, 2 - lemmatizing \n",
    "mod=2\n",
    "\n",
    "# Pre-process texts\n",
    "text_preproc = (\n",
    "    ec_data.Text\n",
    "    .astype(str)\n",
    "    .progress_apply(lambda row: tokenize(row, mod))\n",
    ")\n",
    "\n",
    "ec_data[\"text_preproc\"]=text_preproc\n",
    "\n",
    "print(\"Done with text!\")\n",
    "\n",
    "# Pre-process titles\n",
    "tit_preproc = (\n",
    "    ec_data.Title\n",
    "    .astype(str)\n",
    "    .progress_apply(lambda row: tokenize(row, mod))\n",
    ")\n",
    "\n",
    "ec_data[\"titles_preproc\"]=tit_preproc\n",
    "\n",
    "print(\"Done with titles!\")\n",
    "ec_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9119a",
   "metadata": {},
   "source": [
    "#### Add a binary column to detect mentions of Ukraine:\n",
    "\n",
    "We're enriching our dataset by introducing a binary column to indicate the presence of mentions related to Ukraine. In this new column, a value of 1 will signify that the text contains at least one mention of \"Ukraine\" or \"Ukrainian\", and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74943be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with 1 if 'Text' contains \"ukraine\"/\"ukrainian\", 0 otherwise\n",
    "ec_data['Ukraine'] = ec_data['Text'].str.lower().str.contains('ukrain').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c39babe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the final df\n",
    "ec_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93da642",
   "metadata": {},
   "source": [
    "#### Save the pre-processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d6d0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_data.to_csv('data/theeuropeancommission_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27e661",
   "metadata": {},
   "source": [
    "## The White House data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968aca9",
   "metadata": {},
   "source": [
    "#### Clean the Date column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f994ce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fact Sheet: President-elect Biden Outlines COV...</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Statements and Releases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effectively and equitably vaccinating the U.S....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fact Sheet: List of Agency Actions for Review</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>Statements and Releases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Actions Address the COVID-19 Pandemic, Provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fact Sheet: President Biden Sends Immigration ...</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>Statements and Releases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The U.S. Citizenship Act of 2021 establishes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Letter to Dr. Eric S. Lander, the President’...</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>Statements and Releases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On January 15, 2021, then-President-Elect Bide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paris Climate Agreement</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>Statements and Releases</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACCEPTANCE ON BEHALF OF THE UNITED STATES OF A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Date  \\\n",
       "0  Fact Sheet: President-elect Biden Outlines COV... 2021-01-15   \n",
       "1      Fact Sheet: List of Agency Actions for Review 2021-01-20   \n",
       "2  Fact Sheet: President Biden Sends Immigration ... 2021-01-20   \n",
       "3  A Letter to Dr. Eric S. Lander, the President’... 2021-01-20   \n",
       "4                            Paris Climate Agreement 2021-01-20   \n",
       "\n",
       "                  Category Location  \\\n",
       "0  Statements and Releases      NaN   \n",
       "1  Statements and Releases      NaN   \n",
       "2  Statements and Releases      NaN   \n",
       "3  Statements and Releases      NaN   \n",
       "4  Statements and Releases      NaN   \n",
       "\n",
       "                                                Text  \n",
       "0  Effectively and equitably vaccinating the U.S....  \n",
       "1  Actions Address the COVID-19 Pandemic, Provide...  \n",
       "2  The U.S. Citizenship Act of 2021 establishes a...  \n",
       "3  On January 15, 2021, then-President-Elect Bide...  \n",
       "4  ACCEPTANCE ON BEHALF OF THE UNITED STATES OF A...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove everything after 'T' character\n",
    "wh_data['Date'] = wh_data['Date'].str.split('T').str[0]\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "wh_data['Date'] = pd.to_datetime(wh_data['Date'])\n",
    "\n",
    "# Filter out dates between 2021 and 2023\n",
    "wh_data = wh_data[(wh_data['Date'] >= '2021-01-01') & (wh_data['Date'] <= '2023-12-31')]\n",
    "\n",
    "# Sort the dataset in the ascending order of date\n",
    "wh_data = wh_data.sort_values(by = 'Date', ignore_index=True)\n",
    "\n",
    "wh_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c985c",
   "metadata": {},
   "source": [
    "#### Ensure that the category names are aligned between the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cf0444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Statements and Releases', 'Speeches and Remarks',\n",
       "       'Press Briefings'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_data.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3ad75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the replacement dictionary\n",
    "replacement_dict = {\n",
    "    'Press Briefings': 'Press Release',\n",
    "    'Statements and Releases': 'Statement',\n",
    "    'Speeches and Remarks': 'Speech'\n",
    "}\n",
    "\n",
    "# Replace values in the 'column_name' column using the replace() method\n",
    "wh_data['Category'] = wh_data['Category'].replace(replacement_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c2530",
   "metadata": {},
   "source": [
    "#### Drop the location column as it is not relevant for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60e244b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_data = wh_data.drop('Location', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318e688",
   "metadata": {},
   "source": [
    "#### Check for Null values and duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e602298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title       0\n",
       "Date        0\n",
       "Category    0\n",
       "Text        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "wh_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdf522",
   "metadata": {},
   "source": [
    "We've identified one record with a null value in the Text column. Additionally, during our data exploration, we found another record containing only '###' in the Text column. These entries will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0adf8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Text = Null and Text = ### rows from the data set\n",
    "wh_data = wh_data[(wh_data['Text'].notnull()) & (wh_data['Text'] != '###')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f175da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "wh_data.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81100f42",
   "metadata": {},
   "source": [
    "As we can see, there some duplicate rows in this dataset. Let's check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b7ce4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Remarks By Vice President Harris In A Virtual ...</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>Speech</td>\n",
       "      <td>6:02 P.M. EDT\\n\\nTHE VICE PRESIDENT:  Hi, Rabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Remarks By Vice President Harris In A Virtual ...</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>Speech</td>\n",
       "      <td>6:02 P.M. EDT\\n\\nTHE VICE PRESIDENT:  Hi, Rabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>Background Press Call on President Biden’s Exe...</td>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>Press Release</td>\n",
       "      <td>MODERATOR:  Great, thank you.  Hey, everyone. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>Background Press Call on President Biden’s Exe...</td>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>Press Release</td>\n",
       "      <td>MODERATOR:  Great, thank you.  Hey, everyone. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>Remarks by President Biden and President Volod...</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>Speech</td>\n",
       "      <td>2:46 P.M. JST\\n\\nPRESIDENT BIDEN:  Well, Mr. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>Remarks by President Biden and President Volod...</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>Speech</td>\n",
       "      <td>2:46 P.M. JST\\n\\nPRESIDENT BIDEN:  Well, Mr. P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title       Date  \\\n",
       "405   Remarks By Vice President Harris In A Virtual ... 2021-03-25   \n",
       "408   Remarks By Vice President Harris In A Virtual ... 2021-03-25   \n",
       "4521  Background Press Call on President Biden’s Exe... 2022-09-15   \n",
       "4538  Background Press Call on President Biden’s Exe... 2022-09-15   \n",
       "6338  Remarks by President Biden and President Volod... 2023-05-21   \n",
       "6339  Remarks by President Biden and President Volod... 2023-05-21   \n",
       "\n",
       "           Category                                               Text  \n",
       "405          Speech  6:02 P.M. EDT\\n\\nTHE VICE PRESIDENT:  Hi, Rabb...  \n",
       "408          Speech  6:02 P.M. EDT\\n\\nTHE VICE PRESIDENT:  Hi, Rabb...  \n",
       "4521  Press Release  MODERATOR:  Great, thank you.  Hey, everyone. ...  \n",
       "4538  Press Release  MODERATOR:  Great, thank you.  Hey, everyone. ...  \n",
       "6338         Speech  2:46 P.M. JST\\n\\nPRESIDENT BIDEN:  Well, Mr. P...  \n",
       "6339         Speech  2:46 P.M. JST\\n\\nPRESIDENT BIDEN:  Well, Mr. P...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_data[wh_data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a527dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from the dataset\n",
    "wh_data = wh_data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0a92b",
   "metadata": {},
   "source": [
    "#### Pre-process titles and texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddff6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7846/7846 [44:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with text!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 7846/7846 [00:34<00:00, 229.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with titles!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7846 entries, 0 to 7850\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Title           7846 non-null   object        \n",
      " 1   Date            7846 non-null   datetime64[ns]\n",
      " 2   Category        7846 non-null   object        \n",
      " 3   Text            7846 non-null   object        \n",
      " 4   text_preproc    7846 non-null   object        \n",
      " 5   titles_preproc  7846 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 429.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 - lowercase, 1 - stemming, 2 - lemmatizing \n",
    "mod=2\n",
    "\n",
    "# Pre-process texts\n",
    "text_preproc = (\n",
    "    wh_data.Text\n",
    "    .astype(str)\n",
    "    .progress_apply(lambda row: tokenize(row, mod))\n",
    ")\n",
    "\n",
    "wh_data[\"text_preproc\"]=text_preproc\n",
    "\n",
    "print(\"Done with text!\")\n",
    "\n",
    "# Pre-process titles\n",
    "tit_preproc = (\n",
    "    wh_data.Title\n",
    "    .astype(str)\n",
    "    .progress_apply(lambda row: tokenize(row, mod))\n",
    ")\n",
    "\n",
    "wh_data[\"titles_preproc\"]=tit_preproc\n",
    "\n",
    "print(\"Done with titles!\")\n",
    "wh_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea9319",
   "metadata": {},
   "source": [
    "#### Add a binary column to detect mentions of Ukraine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd470f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with 1 if 'Text' contains \"ukraine\"/\"ukrainian\", 0 otherwise\n",
    "wh_data['Ukraine'] = wh_data['Text'].str.lower().str.contains('ukrain').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48721514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7846, 7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the final df\n",
    "wh_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc52a5",
   "metadata": {},
   "source": [
    "#### Save the pre-processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f153b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_data.to_csv('data/thewhitehouse_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02f8f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File is too big to be pushed on git, so we splitted in into two\n",
    "split_index = len(wh_data) // 2  # Calculate the index to split the DataFrame\n",
    "wh_data_part1 = wh_data.iloc[:split_index]  # Select first half of rows\n",
    "wh_data_part2 = wh_data.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff195c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_data_part1.to_csv('data/thewhitehouse_preprocessed_p1.csv', index=False)\n",
    "wh_data_part2.to_csv('data/thewhitehouse_preprocessed_p2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca519f1",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10cbf80",
   "metadata": {},
   "source": [
    "In this pre-processing notebook, we successfully cleaned and prepared the European Commission and White House datasets for analysis. By standardizing date formats, filtering data, unifying category names, excluding non-English texts (for the European Commission dataset), lemmatizing text data, and adding a binary column for mentions of Ukraine, we have ensured data consistency and usability.\n",
    "\n",
    "These pre-processing steps lay a solid foundation for insightful analysis and informed decision-making. With the data now refined and ready for exploration, we can delve into further analyses to uncover meaningful insights and trends. Through rigorous pre-processing, we have maximized the potential of our datasets and set the stage for comprehensive analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
