{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15eda0e7",
   "metadata": {},
   "source": [
    "# Introduction to the Data Scraping Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87381048",
   "metadata": {},
   "source": [
    "In this data scraping notebook, our objective is to gather relevant information from two key sources â€“ The White House and The European Commission. By systematically collecting and processing data, we aim to provide valuable insights into the nature of their support, potential differences in rhetoric, and the impact of President Zelenskiy's visits.\n",
    "\n",
    "The notebook includes pipelines for scraping the data from The White House and The European Commission. The scraping classes are implemented in a scr/scraper.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728c5d7",
   "metadata": {},
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78d4a1",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import src.scraper as s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520acff8",
   "metadata": {},
   "source": [
    "# Scrape The White House Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de53e2",
   "metadata": {},
   "source": [
    "In this section, we retrieve data from The White House, focusing on President Biden's administration. This includes parsing official statements, speeches, and and press briefings. \n",
    "\n",
    "The data from The White House will be crucial in understanding the United States' stance and support for Ukraine, particularly in the context of President Zelenskiy's visits. It forms a foundational component of our comparative analysis with The European Commission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d68d9",
   "metadata": {},
   "source": [
    "## Scraping Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dataframe to store the results\n",
    "wh_articles_df = pd.DataFrame(columns=['Title', 'Date', 'Category', 'Location', 'Text'])\n",
    "\n",
    "# List of categories to be scraped\n",
    "wh_links = ['https://www.whitehouse.gov/briefing-room/speeches-remarks/',\n",
    "            'https://www.whitehouse.gov/briefing-room/statements-releases/',\n",
    "            'https://www.whitehouse.gov/briefing-room/press-briefings/']        \n",
    "\n",
    "# Iterate through all categories\n",
    "for link in wh_links:\n",
    "    # Get the category\n",
    "    category = link.split('/')[-2]\n",
    "    print(category)\n",
    "    # Initialize the scraping class\n",
    "    scraper = s.TheWhiteHouseScraper(url=link)\n",
    "    soup = scraper.get_html_content()\n",
    "    \n",
    "    # Get the total number of pages\n",
    "    page_num = scraper.get_page_num(soup)\n",
    "    print(f'Total number of pages: {page_num}')\n",
    "\n",
    "    # Get articles from each page\n",
    "    for i in range(1, page_num+1):\n",
    "        page_link = f'{link}page/{i}/'\n",
    "        page_scraper = s.TheWhiteHouseScraper(url=page_link)\n",
    "        page_soup = page_scraper.get_html_content()\n",
    "        \n",
    "        # Add articles to a dataframe\n",
    "        df_temp = pd.DataFrame(page_scraper.get_articles(page_soup, category))\n",
    "        wh_articles_df = pd.concat([wh_articles_df, df_temp], ignore_index=True)\n",
    "\n",
    "        # Print progress every 10%\n",
    "        if i % (page_num // 10) == 0:\n",
    "            print(f'{i}/{page_num} completed.')\n",
    "    print()\n",
    "\n",
    "print(\"Scraping completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4dd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "wh_articles_df.to_csv('data/thewhitehouse.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d38f9",
   "metadata": {},
   "source": [
    "# Scrape The European Commission Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27429bb1",
   "metadata": {},
   "source": [
    "In this phase, our focus shifts to collecting data from The European Commission, which plays a significant role in the European Union's policies and actions.\n",
    "\n",
    "We specifically are going to focus on the speeches and remarks of Ursula von der Leyen, the current President of the European Commission. The data collected will offer insights into the European Commission's stance and support for Ukraine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://ec.europa.eu/commission/presscorner/home/en'\n",
    "geko_path = '/Users/viktoriia/Desktop/BSE/Term 2/NLP/NLP-Project/geckodriver'\n",
    "profile_path = '/Users/viktoriia/Library/Application Support/Firefox/Profiles/k7kr4dw0.Viktoriia'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073d8be",
   "metadata": {},
   "source": [
    "## Scraping Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dataframe to store the results\n",
    "ec_articles_df = pd.DataFrame(columns=['Title', 'Date', 'Category', 'Location', 'Text'])\n",
    "\n",
    "# Initialize type flag\n",
    "first_type = True\n",
    "\n",
    "# CSS for all types of documents we are interested in\n",
    "document_types_css = {'STATEMENT' : '#filter-documentType > option:nth-child(13)', \n",
    "                  'SPEECH': '#filter-documentType > option:nth-child(12)',\n",
    "                  'PRESS RELEASE': '#filter-documentType > option:nth-child(9)'}\n",
    "\n",
    "\n",
    "for document_type in ['STATEMENT', 'SPEECH', 'PRESS RELEASE']:\n",
    "    if first_type:\n",
    "        # Initialize the scraper and open the main page\n",
    "        scraper = s.TheEuropeanCommissionScraper()\n",
    "        browser = scraper.start_up(link, geko_path, profile_path)\n",
    "    else:\n",
    "        # Open the main page\n",
    "        browser = scraper.start_up(link, geko_path, profile_path, browser)\n",
    "\n",
    "    browser = scraper.fill_in_filters(browser, document_type = document_types_css[document_type])    \n",
    "    \n",
    "    # Iterate the pages \n",
    "    while scraper.element_exists(browser, path='//a[@title=\"Go to next page\"]', e_type='xpath'):\n",
    "        # fix this, because we are missing the data from the last page\n",
    "        browser, temp_list = scraper.get_articles(browser)\n",
    "        df_temp = pd.DataFrame(temp_list)\n",
    "        ec_articles_df = pd.concat([ec_articles_df, df_temp], ignore_index=True)\n",
    "        browser.find_element('xpath','//a[@title=\"Go to next page\"]').click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    first_type = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26148f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "ec_articles_df.to_csv('theeuropeancommission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492010d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
